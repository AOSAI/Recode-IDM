model:
  large_size: 128
  small_size: 64
  num_channels: 128
  num_res_blocks: 2
  num_heads: 4
  num_heads_upsample: -1
  learn_sigma: False
  class_cond: False
  use_checkpoint: False
  attention_resolutions: "32,16,8"
  use_scale_shift_norm: False
  dropout: 0.1

diffusion:
  steps: 1000
  learn_sigma: False
  sigma_small: False
  noise_schedule: "cosine"
  use_kl: False
  predict_xstart: False
  rescale_timesteps: False
  rescale_learned_sigmas: False
  timestep_respacing: "ddim250"

training:
  data_dir: "D:\\CodeReproduction\\afhq_v2\\train"
  schedule_sampler: "uniform"
  lr: 1.0e-4
  weight_decay: 0.0
  lr_anneal_steps: 16000
  batch_size: 32
  microbatch: 16
  ema_rate: "0.9999"
  log_interval: 20
  save_interval: 2000
  resume_checkpoint: ""
  use_fp16: False
  fp16_scale_growth: 1.0e-3
